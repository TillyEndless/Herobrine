---
title: 【科研】模型训练加速
published: 2025-07-23
description: ''
image: ''
tags: [灵感]
category: '嗑盐'
draft: false 
lang: ''
---

我自己修改了一下num_workers，从1改为4，速度提高了3倍（4卡12h/epoch -> 6卡3h/epoch），说明有效突破瓶颈。
## 如何加速训练？

我们可以从数据加载、模型计算和训练策略三个层面来提速。

### 1. 优化数据加载（最直接、最容易）

  * **增加`num_workers`**：这是`DataLoader`中一个至关重要的参数，它决定了用多少个子进程来预加载数据。如果设为1（如您当前的`run.py`所示），意味着数据加载和模型计算是在“你等我，我等你”的模式下进行的。
      * **修改建议**：在`run.py`中创建`train_dataloader`时，将`num_workers`的值调高。
        ```python
        # run.py
        train_dataloader = torch.utils.data.DataLoader(
            train_dataset, 
            num_workers=4, # <-- ✨ 从1增加到4或更高
            pin_memory=True,
            # ... a_o_t_h_e_r p_a_r_a_m_e_t_e_r_s ...
        )
        ```
      * **效果**：这可以让CPU在GPU进行当前批次计算的同时，并行地准备好接下来几个批次的数据，从而大大减少GPU的等待时间。您可以从`4`开始尝试，根据您服务器CPU核心数逐步增加。

### 2. 启用混合精度训练（最有效）

使用`bfloat16`或`float16`可以在不严重影响模型精度的情况下，将模型占用的显存减半，并利用现代GPU（如A100）的Tensor Cores进行矩阵运算加速，通常能带来**1.5倍到2倍**的训练速度提升。

  * **修改建议**：在您的`args/gsm_coconut.yaml`配置文件中，将`bf16`设置为`True`。
    ```yaml
    # args/gsm_coconut.yaml
    seed: 0
    resume: 0
    bf16: True # <-- ✨ 从 False 改为 True
    ```
  * **注意**：这需要在您的`run.py`中配合PyTorch的`autocast`上下文管理器使用，FSDP通常有专门的配置项来支持混合精度训练。

### 3. 编译模型（PyTorch 2.0+ 功能）

如果您的PyTorch版本是2.0或更高，可以使用`torch.compile`来优化您的模型，它会将模型的部分计算图编译成更高效的底层代码。

  * **修改建议**：在`run.py`中，将FSDP包裹的模型再用`torch.compile`包裹一次。
    ```python
    # run.py
    parallel_model = FSDP(...)
    parallel_model = torch.compile(parallel_model) # <-- ✨ 新增这一行
    ```

### 4. 减少每个语言步骤的“思考”次数

这是一个超参数调整。在您的配置中，`c_thought: 2`意味着每个语言推理步骤都会被替换为2个连续思维步骤。您可以尝试将其减少到1，来观察对速度和性能的影响。

  * **修改建议**：在`args/gsm_coconut.yaml`中调整。
    ```yaml
    # args/gsm_coconut.yaml
    cot: False
    c_thought: 1 # <-- ✨ 从2减少到1，可以减少循环次数
    ```

---

### 总结
1.  **首要操作**：请先尝试**增加`num_workers`到4或8**，这是最简单且通常有效的优化。
2.  **效果最强**：如果您的硬件支持，**启用`bf16`混合精度训练**带来的速度提升最为显著。
3.  **高级选项**：如果您的PyTorch版本支持，尝试**使用`torch.compile`**。

